{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction using Machine Learning\n",
    "\n",
    "This notebook demonstrates how to predict house prices using machine learning techniques. We'll go through the following steps:\n",
    "\n",
    "1. Data Loading and Exploration\n",
    "   - Load training and test datasets\n",
    "   - Examine data structure and features\n",
    "   - Check for missing values\n",
    "\n",
    "2. Data Preprocessing\n",
    "   - Handle missing values\n",
    "   - Convert categorical variables to numerical\n",
    "   - Select important features\n",
    "\n",
    "3. Model Building\n",
    "   - Split data into training and validation sets\n",
    "   - Train a Random Forest model\n",
    "   - Evaluate model performance\n",
    "\n",
    "4. Make Predictions\n",
    "   - Predict house prices on test data\n",
    "   - Create submission file\n",
    "\n",
    "This is a great beginner project to learn:\n",
    "- Data preprocessing and cleaning\n",
    "- Feature engineering\n",
    "- Machine learning model training\n",
    "- Model evaluation and prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage      259\n",
       "Alley           1369\n",
       "MasVnrType       872\n",
       "MasVnrArea         8\n",
       "BsmtQual          37\n",
       "BsmtCond          37\n",
       "BsmtExposure      38\n",
       "BsmtFinType1      37\n",
       "BsmtFinType2      38\n",
       "Electrical         1\n",
       "FireplaceQu      690\n",
       "GarageType        81\n",
       "GarageYrBlt       81\n",
       "GarageFinish      81\n",
       "GarageQual        81\n",
       "GarageCond        81\n",
       "PoolQC          1453\n",
       "Fence           1179\n",
       "MiscFeature     1406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "train_data.head()\n",
    "\n",
    "# Data Preprocessing\n",
    "# Check for missing values\n",
    "missing_values = train_data.isnull().sum()\n",
    "missing_values[missing_values > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m\n\u001b[0;32m     34\u001b[0m train_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(train_data, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Split the data into training and validation sets\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "train_data.head()\n",
    "\n",
    "# Data Preprocessing\n",
    "# Check for missing values\n",
    "missing_values = train_data.isnull().sum()\n",
    "missing_values[missing_values > 0]\n",
    "\n",
    "# Handle missing values (example strategies)\n",
    "train_data.fillna({\n",
    "    'LotFrontage': train_data['LotFrontage'].mean(),\n",
    "    'Alley': 'No Alley',\n",
    "    'BsmtQual': 'No Basement',\n",
    "    'GarageType': 'No Garage',\n",
    "    'PoolQC': 'No Pool',\n",
    "    'FirePlaceQu': 'No Fireplace',\n",
    "    'Fence': 'No Fence',\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical (one-hot encoding)\n",
    "train_data = pd.get_dummies(train_data, drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "# Model evaluation\n",
    "mse = mean_squared_error(y_val, val_predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Visualize feature importance\n",
    "importances = model.feature_importances_\n",
    "sns.barplot(x=importances, y=features)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance calculation using all features\n",
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})  # Use all features\n",
    "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(20)['Feature']\n",
    "\n",
    "# Correlation heatmap for top 20 features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(train_data[top_features].corr(), annot=True, fmt=\".2f\", cmap='viridis')  # Using 'viridis' for clarity\n",
    "plt.title('Correlation Heatmap of Top 20 Important Features')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of SalePrice\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_data['SalePrice'], bins=30, kde=True)\n",
    "plt.title('SalePrice Distribution')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
