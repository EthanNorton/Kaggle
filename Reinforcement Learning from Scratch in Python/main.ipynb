{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_policy_df = pd.read_csv('OptimalPolicy_angletol45.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  state_x  state_y move_dir throw_dir Action  move_x  move_y  \\\n",
      "0           0      -10      -10        1      none   MOVE       1       1   \n",
      "1           1      -10       -9        1      none   MOVE       1       1   \n",
      "2           2      -10       -8        1      none   MOVE       1       1   \n",
      "3           3      -10       -7        1      none   MOVE       1       1   \n",
      "4           4      -10       -6        1      none   MOVE       1       1   \n",
      "\n",
      "   throw_dir_2    u    v  \n",
      "0        -1000  0.1  0.1  \n",
      "1        -1000  0.1  0.1  \n",
      "2        -1000  0.1  0.1  \n",
      "3        -1000  0.1  0.1  \n",
      "4        -1000  0.1  0.1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1140 entries, 0 to 1139\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   1140 non-null   int64  \n",
      " 1   state_x      1140 non-null   int64  \n",
      " 2   state_y      1140 non-null   int64  \n",
      " 3   move_dir     1140 non-null   object \n",
      " 4   throw_dir    1140 non-null   object \n",
      " 5   Action       1140 non-null   object \n",
      " 6   move_x       1140 non-null   int64  \n",
      " 7   move_y       1140 non-null   int64  \n",
      " 8   throw_dir_2  1140 non-null   int64  \n",
      " 9   u            1140 non-null   float64\n",
      " 10  v            1140 non-null   float64\n",
      "dtypes: float64(2), int64(6), object(3)\n",
      "memory usage: 98.1+ KB\n",
      "None\n",
      "        Unnamed: 0      state_x      state_y       move_x       move_y  \\\n",
      "count  1140.000000  1140.000000  1140.000000  1140.000000  1140.000000   \n",
      "mean    569.500000     0.000000     0.000000  -329.824561  -329.824561   \n",
      "std     329.233959     5.082118     5.082118   470.356216   470.356216   \n",
      "min       0.000000   -10.000000   -10.000000 -1000.000000 -1000.000000   \n",
      "25%     284.750000    -2.000000    -2.000000 -1000.000000 -1000.000000   \n",
      "50%     569.500000     0.000000     0.000000    -1.000000    -1.000000   \n",
      "75%     854.250000     2.000000     2.000000     1.000000     1.000000   \n",
      "max    1139.000000    10.000000    10.000000     1.000000     1.000000   \n",
      "\n",
      "       throw_dir_2            u            v  \n",
      "count  1140.000000  1140.000000  1140.000000  \n",
      "mean   -663.982456     0.000000     0.031579  \n",
      "std     476.014253     0.077039     0.089987  \n",
      "min   -1000.000000    -0.100000    -0.100000  \n",
      "25%   -1000.000000    -0.100000    -0.100000  \n",
      "50%   -1000.000000     0.000000     0.100000  \n",
      "75%       0.000000     0.100000     0.100000  \n",
      "max     315.000000     0.100000     0.100000  \n"
     ]
    }
   ],
   "source": [
    "print(optimal_policy_df.head())\n",
    "print(optimal_policy_df.info())\n",
    "print(optimal_policy_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, state_size, action_size, learning_rate, discount_factor):\n",
    "        self.q_table = np.zeros((state_size, action_size))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        # Implement the action selection logic\n",
    "        pass\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        # Implement the Q-learning update rule\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
